

![image-20241105184321964](C:\Users\86139\AppData\Roaming\Typora\typora-user-images\image-20241105184321964.png)





------



## 实验目标:

1. 对于课件中“多个数组排序”的任务不均衡案例进行复现（规模可自己调整），并探索较优的方案。提示：可从任务分块的大小、线程数的多少、静态动态多线程结合等方面进行尝试，探索规律。
2. 实现高斯消去法解线性方程组的Pthread多线程编程，可与SSE/AVX编程结合，并探索优化任务分配方法。
3. **附加题：**使用其他方式（如忙等待、互斥量、信号量等），自行实现不少于2种路障Barrier的功能，分析与Pthread_barrier相关接口功能的异同。提示：可采用课件上路障部分的案例，用其他2种方式实现相同功能；也可自行设定场景，实现2种或以上barrier的功能，并进行效率、功能等方面的展示比较。

## 实验要求:

- 写成一份实验报告，将实验报告及源码（*.cpp和*.cbp文件，如果使用非CodeBlocks可将代码全部打包并注明使用的工具）。多个文件需要打包为“姓名-学号-并行第03次作业.zip”格式

## 实验流程:

1. 编写多个数组排序初始版本(静态分配):

   ```C++
   void *arr_sort(void *parm)
   {
       threadParm_t *p = (threadParm_t *) parm;
       int r = p->threadId;
       long long tail;
       for (int i = r * seg; i < (r + 1) * seg; i++)
           sort(arr[i].begin(), arr[i].end());
       pthread_mutex_lock(&mutex);
       QueryPerformanceCounter((LARGE_INTEGER *)&tail);
       printf("Thread %d: %lfms.\n", r, (tail - head) * 1000.0 / freq);
       pthread_mutex_unlock(&mutex);
       pthread_exit(NULL);
   }
   ```

2. 编写多个数组排序,细粒度动态分配

   ```c++
   int next_arr = 0;
   pthread_mutex_t mutex_task;
   void *arr_sort_fine(void *parm){
       threadParm_t *p = (threadParm_t *) parm;
       int r = p->threadId;
       int task = 0;
       long long tail;
       while (1) {
       pthread_mutex_lock(&mutex_task);
       task = next_arr++;
       pthread_mutex_unlock(&mutex_task);
       if (task >= ARR_NUM) break;
           stable_sort(arr[task].begin(), arr[task].end());
       }
       pthread_mutex_lock(&mutex);
       QueryPerformanceCounter((LARGE_INTEGER *)&tail);
       printf("Thread %d: %lfms.\n", r, (tail - head) * 1000.0 / freq);
       pthread_mutex_unlock(&mutex);
       pthread_exit(NULL);
   }
   ```

3. 编写多个数组排序,粗粒度动态分配

   ```c++
   void *arr_sort_fine2(void *parm) {
       threadParm_t *p = (threadParm_t *) parm;
       int r = p->threadId;
       int task = 0;
       long long tail;
       const int task_size = 50; // 每次分配50行
   
       while (true) {
           pthread_mutex_lock(&mutex_task);
           task = next_arr;
           next_arr += task_size;  // 一次分配50行
           pthread_mutex_unlock(&mutex_task);
   
           if (task >= ARR_NUM) break;
   
           // 对当前分配的任务范围内的行进行排序
           int end = min(task + task_size, ARR_NUM);  // 防止越界
           for (int i = task; i < end; i++) {
               stable_sort(arr[i].begin(), arr[i].end());
           }
       }
   
       pthread_mutex_lock(&mutex);
       QueryPerformanceCounter((LARGE_INTEGER *)&tail);
       printf("Thread %d: %lfms.\n", r, (tail - head) * 1000.0 / freq);
       pthread_mutex_unlock(&mutex);
   
       pthread_exit(NULL);
   }
   ```

4. 进行实验,比较不同方法执行时间的差异,比对不同程序的效率

   - 对照组:(线程数4,数据规模10000)

   静态分配:

   ![image-20241105192248178](C:\Users\86139\AppData\Roaming\Typora\typora-user-images\image-20241105192248178.png)

   细粒度动态分配:

   ![image-20241105192347709](C:\Users\86139\AppData\Roaming\Typora\typora-user-images\image-20241105192347709.png)

   粗粒度动态分配:

   ![image-20241105192624701](C:\Users\86139\AppData\Roaming\Typora\typora-user-images\image-20241105192624701.png)

   在规模恒定为10000时,通过对比发现静态分配耗时最长,细粒度动态分配耗时相对较少,而粗粒度动态分配用时最少,这是因为静态分配时,并没有达到负载均衡,所以效率偏低,每个线程运行时间长短不一,而且每个线程一次性分配过多任务,可能会导致cache效率低,而细粒度效率不如粗粒度则是因为线程切换需要一定的资源,粗粒度切换更少的同时也达到了负载相对均衡

   - 调整线程数目,设置为8:(线程数8,数据规模10000)

   静态分配:

   ![image-20241105192952485](C:\Users\86139\AppData\Roaming\Typora\typora-user-images\image-20241105192952485.png)

   细粒度动态分配:

   ![image-20241105193206018](C:\Users\86139\AppData\Roaming\Typora\typora-user-images\image-20241105193206018.png)

   与之前的数据比对可以发现线程数增加后,程序运行更快了,与此同时,静态分配的负载不均衡问题更加明显,而动态分配两种方式的优势更加明显

   - 调整数据规模为5000,20000(线程数4,数据规模5000,20000)

   5000规模:

   静态分配:

   ![image-20241105193956758](C:\Users\86139\AppData\Roaming\Typora\typora-user-images\image-20241105193956758.png)

   细粒度动态分配:

   ![image-20241105194021049](C:\Users\86139\AppData\Roaming\Typora\typora-user-images\image-20241105194021049.png)

   粗粒度动态分配:

   ![image-20241105194036214](C:\Users\86139\AppData\Roaming\Typora\typora-user-images\image-20241105194036214.png)

   20000规模:

   静态分配:

   ![image-20241105195157462](C:\Users\86139\AppData\Roaming\Typora\typora-user-images\image-20241105195157462.png)

   细粒度动态分配:

   ![image-20241105195028560](C:\Users\86139\AppData\Roaming\Typora\typora-user-images\image-20241105195028560.png)

   粗粒度:

   ![image-20241105195719291](C:\Users\86139\AppData\Roaming\Typora\typora-user-images\image-20241105195719291.png)

   在5000大小情况下,我发现三种方法差异并不明显,可能原因是数据规模较小时,负载不均衡问题不明显,三种方式都能有较好的表现

   在20000大小情况下,反而是静态分配最快,可能原因是线程加锁解锁消耗了部分资源,导致最后整体效率偏低,但是粗粒度仍然有较高的效率,因为每次分配了一定量数据,无需过多申请

5. 使用pthread优化高斯消元:

   ```c++
   #include <iostream>
   #include <iomanip>
   #include <random>
   #include <chrono>
   #include <pthread.h>
   
   const int N1 = 500;
   const int N2 = 1000;
   const int N3 = 2000;
   const int THREAD_COUNT = 8;
   
   struct ThreadData {
       float** matrix;
       int size;
       int row;
       int startRow;
       int endRow;
   };
   
   void generateMatrix(float** matrix, int size) {
       std::random_device rd;
       std::mt19937 gen(rd());
       std::uniform_real_distribution<> dis(1.0, 100.0);
   
       for (int i = 0; i < size; ++i)
           for (int j = 0; j < size; ++j)
               matrix[i][j] = dis(gen);
   }
   
   // 普通高斯消元的线程函数
   void* gaussianEliminationThread(void* arg) {
       ThreadData* data = static_cast<ThreadData*>(arg);
       float** matrix = data->matrix;
       int size = data->size;
       int row = data->row;
       int startRow = data->startRow;
       int endRow = data->endRow;
   
       float pivot = matrix[row][row];
       for (int j = row; j < size; ++j) {
           matrix[row][j] /= pivot;
       }
   
       for (int i = startRow; i < endRow; ++i) {
           if (i == row) continue;
           float factor = matrix[i][row];
           for (int j = row; j < size; ++j) {
               matrix[i][j] -= factor * matrix[row][j];
           }
       }
       pthread_exit(nullptr);
   }
   
   void gaussianElimination(float** matrix, int size) {
       for (int k = 0; k < size; ++k) {
           pthread_t threads[THREAD_COUNT];
           ThreadData threadData[THREAD_COUNT];
   
           int rowsPerThread = (size - k - 1) / THREAD_COUNT;
           for (int t = 0; t < THREAD_COUNT; ++t) {
               int startRow = k + 1 + t * rowsPerThread;
               int endRow = (t == THREAD_COUNT - 1) ? size : startRow + rowsPerThread;
   
               threadData[t] = {matrix, size, k, startRow, endRow};
               pthread_create(&threads[t], nullptr, gaussianEliminationThread, &threadData[t]);
           }
   
           for (int t = 0; t < THREAD_COUNT; ++t) {
               pthread_join(threads[t], nullptr);
           }
       }
   }
   
   // 回代过程
   void backSubstitution(float** matrix, float* solution, int size) {
       for (int i = size - 1; i >= 0; --i) {
           solution[i] = matrix[i][size];
           for (int j = i + 1; j < size; ++j) {
               solution[i] -= matrix[i][j] * solution[j];
           }
           solution[i] /= matrix[i][i];
       }
   }
   
   int main() {
       int sizes[] = {N1, N2, N3};
   
       for (int size : sizes) {
           std::cout << "Matrix size: " << size << "x" << size << "\n";
   
           // 初始化矩阵
           float** matrix = new float*[size];
           for (int i = 0; i < size; ++i) {
               matrix[i] = new float[size + 1]; // 增加一列来存放结果
           }
   
           // 生成随机矩阵
           generateMatrix(matrix, size);
   
           // 普通多线程高斯消元
           auto start = std::chrono::high_resolution_clock::now();
           gaussianElimination(matrix, size);
           auto end = std::chrono::high_resolution_clock::now();
           std::chrono::duration<double> elapsed = end - start;
           std::cout << "Multithreaded Gaussian Elimination Time: " << elapsed.count() << " seconds\n";
   
           // 初始化解向量
           float* solution = new float[size];
   
           // 回代
           start = std::chrono::high_resolution_clock::now();
           backSubstitution(matrix, solution, size);
           end = std::chrono::high_resolution_clock::now();
           elapsed = end - start;
           std::cout << "Back Substitution Time: " << elapsed.count() << " seconds\n";
   
           // 释放矩阵内存
           for (int i = 0; i < size; ++i) {
               delete[] matrix[i];
           }
           delete[] matrix;
           delete[] solution;
   
           std::cout << "\n";
       }
       return 0;
   }
   ```

   运行结果:(8线程)

   ![image-20241105202347801](C:\Users\86139\AppData\Roaming\Typora\typora-user-images\image-20241105202347801.png)

   与上次实验结果进行比对:

   500规模大小

   ![image-20241105201933871](C:\Users\86139\AppData\Roaming\Typora\typora-user-images\image-20241105201933871.png)

   1000规模大小:

   ![image-20241105202209961](C:\Users\86139\AppData\Roaming\Typora\typora-user-images\image-20241105202209961.png)

   2000规模大小:

   ![image-20241105203735251](C:\Users\86139\AppData\Roaming\Typora\typora-user-images\image-20241105203735251.png)

   经过对比发现,多线程情况下运行时间显著下降,AVX运行时间很慢可能是因为芯片支持不好,但是SSE比多线程慢两倍左右,并且规模越大,影响越明显,我认为为了提升效率划分任务时,可以优先使用多线程方式,在这种实验条件下有更好的表现结果

6. 附加题

   - 利用利用锁变量与忙等待进行阻塞和唤醒:

     ```c++
      void * func(void * args) {
                 Thread_PARAM *p = (Thread_PARAM *) args;
     
                 pthread_mutex_lock(&print);
                 fprintf(stdout, "Thread %d has entered step 1.\n", p->thread_id);
                 pthread_mutex_unlock(&print);
                 pthread_mutex_lock(&mutexs);
                 counter++;
                 pthread_mutex_unlock(&mutexs);
                 while (counter < num);
                 pthread_mutex_lock(&print);
                 fprintf(stdout, "Thread %d has entered step 2.\n", p->thread_id);
                 pthread_mutex_unlock(&print);
                 pthread_exit(NULL);
             }
     ```
     
   - 利用利用信号量:

     ```c++
     void* threadFunc(void* parm)
     {
         threadParm_t* p = (threadParm_t*)parm;
         fprintf(stdout, "Thread %d has entered step 1.\n", p->threadId);
         sem_wait(&sem_count);
         if (counter == NUM_THREADS - 1)
         {
             counter = 0;
             sem_post(&sem_count);
             for (int i = 0; i < NUM_THREADS - 1; i++) sem_post(&sem_barrier);
         }
         else
         {
             counter++;
             sem_post(&sem_count);
             sem_wait(&sem_barrier);
         }
     
         fprintf(stdout, "Thread %d has entered step 2.\n", p->threadId);
         pthread_exit(NULL);
     }
     ```
     
     编写测试代码:
     
     1. 利用锁变量与忙等待的测试代码,使用100轮
     
        ```c++
                #include<iostream>
                #include<pthread.h>
                #define num 8
                using namespace std;
                typedef struct thread_item{
                    int thread_id;
                }Thread_PARAM;
                pthread_mutex_t mutexs;
                pthread_mutex_t print;
                pthread_cond_t cond;
                int counter=0;
                void * func(void * args) {
                    Thread_PARAM *p = (Thread_PARAM *) args;
        
                    pthread_mutex_lock(&print);
                    fprintf(stdout, "Thread %d has entered step 1.\n", p->thread_id);
                    pthread_mutex_unlock(&print);
                    pthread_mutex_lock(&mutexs);
                    counter++;
                    pthread_mutex_unlock(&mutexs);
                    while (counter < num);
                    pthread_mutex_lock(&print);
                    fprintf(stdout, "Thread %d has entered step 2.\n", p->thread_id);
                    pthread_mutex_unlock(&print);
                    pthread_exit(NULL);
                }
                int main(){
                    int j=0;
                    while(j<100){
                        pthread_mutex_init(&mutexs, NULL);
                        pthread_mutex_init(&print, NULL);
                        pthread_cond_init(&cond, NULL);
                        pthread_t thread[num];
                        Thread_PARAM thread_param[num];
                        for(int i=0;i<num;i++){
                            thread_param[i].thread_id = i;
                            pthread_create(&thread[i],NULL,func,(void*)&thread_param[i]);
                        }
                        for(int j=0;j<num;j++){
                            pthread_join(thread[j],NULL);
                        }
                        j++;
                    }
                    return 0;
                }
        
        ```
     
     2. 利用信号量实现barrier的测试代码:
     
        ```c++
        
        #include <stdio.h>
        #include <stdlib.h>
        #include <pthread.h>
        #include <semaphore.h>
        int counter = 0;
        #define NUM_THREADS 8
        typedef struct {
            int threadId;
        } threadParm_t;
        sem_t sem_count;
        sem_t sem_barrier;
        
        void* threadFunc(void* parm)
        {
            threadParm_t* p = (threadParm_t*)parm;
            fprintf(stdout, "Thread %d has entered step 1.\n", p->threadId);
            sem_wait(&sem_count);
            if (counter == NUM_THREADS - 1)
            {
                counter = 0;
                sem_post(&sem_count);
                for (int i = 0; i < NUM_THREADS - 1; i++) sem_post(&sem_barrier);
            }
            else
            {
                counter++;
                sem_post(&sem_count);
                sem_wait(&sem_barrier);
            }
        
            fprintf(stdout, "Thread %d has entered step 2.\n", p->threadId);
            pthread_exit(NULL);
        }
        int main(int argc, char* argv[])
        {
            int j=0;
            while(j<100){
                sem_init(&sem_count, 0, 1);
                sem_init(&sem_barrier, 0, 0);
                pthread_t thread[NUM_THREADS];
                threadParm_t threadParm[NUM_THREADS];
                int i;
                for (i = 0; i < NUM_THREADS; i++)
                {
                    threadParm[i].threadId = i;
                    pthread_create(&thread[i], NULL, threadFunc, (void *)&threadParm[i]);
                }
                for (i = 0; i < NUM_THREADS; i++)
                {
                    pthread_join(thread[i], NULL);
                }
                sem_destroy(&sem_count);
                sem_destroy(&sem_barrier);
                j++;
            }
            return 0;
        }
        ```
        
     3. 编写原始barrier代码:
     
        ```c++
        #include <stdio.h>
        #include <stdlib.h>
        #include <pthread.h>
        #define NUM_THREADS 8
        typedef struct{
        int threadId;
        }threadParm_t;
        pthread_barrier_t barrier;
        void *threadFunc(void *parm)
        {
        threadParm_t *p = (threadParm_t *) parm;
        fprintf(stdout, "Thread %d has entered step 1.\n", p->threadId);
        pthread_barrier_wait(&barrier);
        fprintf(stdout, "Thread %d has entered step 2.\n", p->threadId);
        pthread_exit(NULL);
        }
        int main(int argc, char *argv[])
        {
            int j=0;
            while(j<1000){
                pthread_barrier_init(&barrier, NULL, NUM_THREADS);
                pthread_t thread[NUM_THREADS];
                threadParm_t threadParm[NUM_THREADS];
                int i;
                for (i=0; i<NUM_THREADS; i++)
                {
                threadParm[i].threadId = i;
                pthread_create(&thread[i], NULL, threadFunc, (void
                *)&threadParm[i]);
                }
                for (i=0; i<NUM_THREADS; i++)
                {
                pthread_join(thread[i], NULL);
                }
                pthread_barrier_destroy(&barrier);
                j++;
            }
        return 0;
        }
        ```
     
     4. 进行测试比较三种方式的效率:
     
        - 100线程测试10次:
     
          - 信号量:
     
            ![image-20241110151702048](C:\Users\86139\AppData\Roaming\Typora\typora-user-images\image-20241110151702048.png)
     
          - 忙等待与锁变量
     
            ![image-20241110152057010](C:\Users\86139\AppData\Roaming\Typora\typora-user-images\image-20241110152057010.png)
     
          - 原始barrier:
     
            ![image-20241110151934654](C:\Users\86139\AppData\Roaming\Typora\typora-user-images\image-20241110151934654.png)
     
          比对三者我发现信号量与原始barrier效率基本一致,而使用忙等待的运行时间明显更长,效率低,我认为这是因为频繁的加减锁和忙等待让程序运行变得臃肿,加减锁操作需要消耗时间与资源,导致最终程序效率低下
     
        - 测试500线程,循环运行5次:
     
          - 信号量
     
            ![image-20241110152410730](C:\Users\86139\AppData\Roaming\Typora\typora-user-images\image-20241110152410730.png)
     
          - 忙等待与锁变量
     
            由于加减锁与忙等待原因,线程数越多,该方法效率越低:
     
            ![image-20241110153514395](C:\Users\86139\AppData\Roaming\Typora\typora-user-images\image-20241110153514395.png)
     
          - 原始barrier:
            ![image-20241110153543811](C:\Users\86139\AppData\Roaming\Typora\typora-user-images\image-20241110153543811.png)
     
        - 测试10次循环20次:
     
          - 信号量
     
            ![image-20241110153659637](C:\Users\86139\AppData\Roaming\Typora\typora-user-images\image-20241110153659637.png)
     
          - 忙等待与锁变量
     
            ![image-20241110153758849](C:\Users\86139\AppData\Roaming\Typora\typora-user-images\image-20241110153758849.png)
     
          - 原始barrier
     
            ![image-20241110153822730](C:\Users\86139\AppData\Roaming\Typora\typora-user-images\image-20241110153822730.png)
     
          测试发现,当线程数较小时,忙等待劣势不明显,可能是由于此时线程数机器可以直接进行分配,无需动态分配线程,而且此时线程数量小,忙等待的影响也小,因此忙等待带来的劣势不明显,至于原始barrier以及信号量实现的barrier依旧效率相差不大
     
        总结:当规模较小时,信号量,忙等待与锁变量和原始barrier效率相差不大,而规模变大之后忙等待效率显著下降,这是由于线程数目过多,机器需要频繁加锁解锁与忙等待,造成大量资源浪费,效率严重降低,而信号量与原始barrier仍然具有相对优秀的效率

7. 总结:

   经过此次实验,我对并行程序编写有了一个更深刻的认识,了解了锁变量,忙等待,信号量与barrier的基本机制以及pthread编程,对向量化编程以及多线程编程有了更深刻的理解,收获很多
